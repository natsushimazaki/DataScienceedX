---
title: "Inference and Modeling Notes"
author: "natsuMishi"
date: "2023-12-28"
output: html_document
---

# Section 1: Parameters and Estimates

# Section 1 Overview

Section 1 introduces you to parameters and estimates.

After completing Section 1, you will be able to:

-   Understand how to use a sampling model to perform a poll.

-   Explain the terms **population**, **parameter**, and **sample** as they relate to statistical inference.

-   Use a sample to estimate the population proportion from the sample average.

-   Calculate the expected value and standard error of the sample average.

# Sampling Model Parameters and Estimates

-   The task of statistical inference is to estimate an unknown population parameter using observed data from a sample.

<!-- -->

-   In a sampling model, the collection of elements in the urn is called the *population.*

<!-- -->

-   A *parameter* is a number that summarizes data for an entire population.

<!-- -->

-   A *sample* is observed data from a subset of the population.

<!-- -->

-   An *estimate* is a summary of the observed data about a parameter that we believe is informative. It is a data-driven guess of the population parameter.

![](images/clipboard-3095055459.png)

-   The sample proportion is a random variable. Sampling gives random results drawn from the population distribution.

### Code: Function for taking a random draw from a specific urn

The **dslabs** package includes a function for taking a random draw of size n from the urn described in the video:

```{r}
library(tidyverse)
library(dslabs)
ds_theme_set()
take_poll(25)    # draw 25 beads
```

### The Sample Average

![](images/clipboard-1596829150.png)

### Polling versus Forecasting

-   A poll taken in advance of an election estimates p for that moment, not for election day.

-   In order to predict election results, forecasters try to use early estimates of p to predict p on election day. We discuss some approaches in later sections.

### Properties of Our Estimate

![![](images/clipboard-610903079.png){width="237"}](images/clipboard-1317090737.png)

![](images/clipboard-1002058319.png)

# Assessment 1.1: Parameters and Estimates

## Exercise 1. Polling - expected value of S

1\. Suppose you poll a population in which a proportion p of voters are Democrats and 1−p are Republicans. Your sample size is N=25. Consider the random variable S which is the **total** number of Democrats in your sample. What is the expected value of this random variable? Hint: it’s a function of p.

Ans. E(S) = 25 \* p

## Exercise 2. Polling - standard error of S

![](images/clipboard-3851961928.png)

2\. What is the standard error of S ? Hint: it’s a function of p.

![](images/clipboard-2080617049.png){width="181"}

## Exercise 3. Polling - expected value of X-bar

![![](images/clipboard-1955129058.png){width="122"}](images/clipboard-2815746691.png)

3\. Consider the random variable S/N. This is equivalent to the sample average, which we have been denoting as ¯X. What is the expected value of the ¯X? Hint: it’s a function of p.

## Exercise 4. Polling - standard error of X-bar

![](images/clipboard-3808667543.png)

![](images/clipboard-378992676.png){width="126"}

4\. What is the standard error of ¯X? Hint: it’s a function of p.

## Exercise 5. se versus p

Write a line of code that calculates the standard error `se` of a sample average when you poll 25 people in the population. Generate a sequence of 100 proportions of Democrats `p` that vary from 0 (no Democrats) to 1 (all Democrats).

Plot `se` versus `p` for the 100 different proportions.

-   Use the `seq` function to generate a vector of 100 values of `p` that range from 0 to 1.

-   Use the `sqrt` function to generate a vector of standard errors for all values of `p`.

-   Use the `plot` function to generate a plot with `p` on the x-axis and `se` on the y-axis.

```{r}
# `N` represents the number of people polled
N <- 25

# Create a variable `p` that contains 100 proportions ranging from 0 to 1 using the `seq` function
p <- seq(0,1, length.out = 100)
p

# Create a variable `se` that contains the standard error of each sample average
se <- sqrt(p*(1-p)/N)
se
# Plot `p` on the x-axis and `se` on the y-axis
plot(p, se)
```

## Exercise 6. Multiple plots of se versus p

![](images/clipboard-1439325597.png)

-   Your for-loop should contain two lines of code to be repeated for three different values of N.

-   The first line within the for-loop should use the `sqrt` function to generate a vector of standard errors `se` for all values of `p`.

-   The second line within the for-loop should use the `plot` function to generate a plot with `p` on the x-axis and `se` on the y-axis.

-   Use the `ylim` argument to keep the y-axis limits constant across all three plots. The lower limit should be equal to 0 and the upper limit should equal 0.1 (it can be shown that this value is the highest calculated standard error across all values of `p` and `N`).

```{r}
# The vector `p` contains 100 proportions of Democrats ranging from 0 to 1 using the `seq` function
p <- seq(0, 1, length = 100)

# The vector `sample_sizes` contains the three sample sizes
sample_sizes <- c(25, 100, 1000)

# Write a for-loop that calculates the standard error `se` for every value of `p` for each of the three samples sizes `N` in the vector `sample_sizes`. Plot the three graphs, using the `ylim` argument to standardize the y-axis across all three plots.
for(n in sample_sizes){
    se <- sqrt(p*(1-p)/sample_sizes)
    plot(p, se, ylim = c(0, 0.1))
}
```

## Exercise 7. Expected value of d

![](images/clipboard-847696336.png)

![](images/clipboard-1315534093.png)

## Exercise 8. Standard error of d

![](images/clipboard-3313486290.png)

![](images/clipboard-2452175276.png)

## Exercise 9. Standard error of the spread

![](images/clipboard-1801572909.png)

```{r}
# `N` represents the number of people polled
N <- 25

# `p` represents the proportion of Democratic voters
p <- 0.45

# Calculate the standard error of the spread. Print this value to the console.
2*sqrt(p*(1-p)/N)
```

## Exercise 10. Sample size

![](images/clipboard-2372263968.png)

![](images/clipboard-2689455482.png)

# Section 2 Overview

![](images/clipboard-4246266515.png)

### The Central Limit Theorem in Practice

![](images/clipboard-4023891576.png)

plug-in estimate

### Code: Computing the probability of Xbar being within .01 of p

```{r}
X_hat <- 0.48
se <- sqrt(X_hat*(1-X_hat)/25)
pnorm(0.01/se) - pnorm(-0.01/se)
```

### Margin of Error

![](images/clipboard-2680709885.png)

### A Monte Carlo Simulation for the CLT

-   We can run Monte Carlo simulations to compare with theoretical results assuming a value of p.

<!-- -->

-   In practice, is unknown. We can corroborate theoretical results by running Monte Carlo simulations with one or several values of p.

We don't know p, but we could run it for various values of p and sample sizes N and see that the theory works well for most values.

-   One practical choice for p when modeling is Xbar, the observed value of in a sample Xhat.![](images/clipboard-2180675967.png)

### Code: Monte Carlo simulation using a set value of p

```{r}
p <- 0.45    # unknown p to estimate
N <- 1000

# simulate one poll of size N and determine x_hat
x <- sample(c(0,1), size = N, replace = TRUE, prob = c(1-p, p))
x_hat <- mean(x)

# simulate B polls of size N and determine average x_hat
B <- 10000    # number of replicates
N <- 1000    # sample size per replicate
x_hat <- replicate(B, {
    x <- sample(c(0,1), size = N, replace = TRUE, prob = c(1-p, p))
    mean(x)
})
```

### Code: Histogram and QQ-plot of Monte Carlo results

```{r}
library(tidyverse)
library(gridExtra)
p1 <- data.frame(x_hat = x_hat) %>%
    ggplot(aes(x_hat)) +
    geom_histogram(binwidth = 0.005, color = "black")
p2 <- data.frame(x_hat = x_hat) %>%
    ggplot(aes(sample = x_hat)) +
    stat_qq(dparams = list(mean = mean(x_hat), sd = sd(x_hat))) +
    geom_abline() +
    ylab("X_hat") +
    xlab("Theoretical normal")
grid.arrange(p1, p2, nrow=1)
```

### The Spread

![](images/clipboard-2485748537.png)

### Bias: Why Not Run a Very Large Poll?

-   An extremely large poll would theoretically be able to predict election results almost perfectly.

-   These sample sizes are not practical. In addition to cost concerns, polling doesn't reach everyone in the population (eventual voters) with equal probability, and it also may include data from outside our population (people who will not end up voting).

-   These systematic errors in polling are called *bias*. We will learn more about bias in the future.

### Code: Plotting margin of error in an extremely large poll over a range of values of p

```{r}
library(tidyverse)
N <- 100000
p <- seq(0.35, 0.65, length = 100)
SE <- sapply(p, function(x) 2*sqrt(x*(1-x)/N))
data.frame(p = p, SE = SE) %>%
    ggplot(aes(p, SE)) +
    geom_line()
```

# Assessment 2.1: Introduction to Inference

## Exercise 1. Sample average

Write function called `take_sample` that takes the proportion of Democrats p and the sample size N as arguments and returns the sample average of Democrats (1) and Republicans (0).

Calculate the sample average if the proportion of Democrats equals 0.45 and the sample size is 100.

![](images/clipboard-1522920268.png)

```{r}
# Write a function called `take_sample` that takes `p` and `N` as arguements and returns the average value of a randomly sampled population.
take_sample <- function(p,N){
    sim <- sample(c(1,0), N, replace = TRUE, prob = c(p, 1-p))   
    mean(sim)
}

# Use the `set.seed` function to make sure your answer matches the expected result after random sampling
set.seed(1)

# Define `p` as the proportion of Democrats in the population being polled
p <- 0.45

# Define `N` as the number of people polled
N <- 100

# Call the `take_sample` function to determine the sample average of `N` randomly selected people from a population containing a proportion of Democrats equal to `p`. Print this value to the console.
take_sample(p, N)
```

## Exercise 2. Distribution of errors - 1

![](images/clipboard-1445621711.png)

-   The function `take_sample` that you defined in the previous exercise has already been run for you.

<!-- -->

-   Use the `replicate` function to replicate subtracting the result of `take_sample` from the value of p 10,000 times.

<!-- -->

-   Use the `mean` function to calculate the average of the differences between the sample average and actual value of p.

```{r}
# Define `p` as the proportion of Democrats in the population being polled
p <- 0.45

# Define `N` as the number of people polled
N <- 100

# The variable `B` specifies the number of times we want the sample to be replicated
B <- 10000

# Use the `set.seed` function to make sure your answer matches the expected result after random sampling
set.seed(1)

# Create an objected called `errors` that replicates subtracting the result of the `take_sample` function from `p` for `B` replications
errors <- replicate(B, {
    differences <- p - take_sample(p,N)
    differences
})

# Calculate the mean of the errors. Print this value to the console.
mean(errors)
```

## Exercise 3. Distribution of errors - 2

![](images/clipboard-2189136323.png)

The `errors` object has already been loaded for you. Use the `hist` function to plot a histogram of the values contained in the vector `errors`. Which statement best describes the distribution of the errors?

![![](images/clipboard-1090704458.png)](images/clipboard-3251208375.png)

## Exercise 4. Average size of error

![](images/clipboard-162436746.png)

```{r}
# Define `p` as the proportion of Democrats in the population being polled
p <- 0.45

# Define `N` as the number of people polled
N <- 100

# The variable `B` specifies the number of times we want the sample to be replicated
B <- 10000

# Use the `set.seed` function to make sure your answer matches the expected result after random sampling
set.seed(1)

# We generated `errors` by subtracting the estimate from the actual proportion of Democratic voters
errors <- replicate(B, p - take_sample(p, N))

# Calculate the mean of the absolute value of each simulated error. Print this value to the console.
mean(abs(errors))

```

## Exercise 5. Standard deviation of the spread

The standard error is related to the typical **size** of the error we make when predicting. We say **size** because, as we just saw, the errors are centered around 0. In that sense, the typical error is 0. For mathematical reasons related to the central limit theorem, we actually use the standard deviation of `errors` rather than the average of the absolute values.

```{r}
# Define `p` as the proportion of Democrats in the population being polled
p <- 0.45

# Define `N` as the number of people polled
N <- 100

# The variable `B` specifies the number of times we want the sample to be replicated
B <- 10000

# Use the `set.seed` function to make sure your answer matches the expected result after random sampling
set.seed(1)

# We generated `errors` by subtracting the estimate from the actual proportion of Democratic voters
errors <- replicate(B, p - take_sample(p, N))

# Calculate the standard deviation of `errors`
sqrt(mean((errors)^2))

```

## Exercise 6. Estimating the standard error

![](images/clipboard-2893701149.png)

-   Calculate the standard error using the `sqrt` function

```{r}
# Define `p` as the expected value equal to 0.45
p <- 0.45

# Define `N` as the sample size
N <- 100

# Calculate the standard error
sqrt(p*(1-p)/N)
```

## Exercise 7. Standard error of the estimate

![](images/clipboard-3509517342.png)

-   Simulate a poll `X` using the `sample` function.

-   When using the `sample` function, create a vector using `c()` that contains all possible polling options where '1' indicates a Democratic voter and '0' indicates a Republican voter.

-   When using the `sample` function, use `replace = TRUE` within the `sample` function to indicate that sampling from the vector should occur with replacement.

-   When using the `sample` function, use `prob =` within the `sample` function to indicate the probabilities of selecting either element (0 or 1) within the vector of possibilities.

-   Use the `mean` function to calculate the average of the simulated poll, `X_bar`.

-   Calculate the standard error of the `X_bar` using the `sqrt` function and print the result.

```{r}
# Define `p` as a proportion of Democratic voters to simulate
p <- 0.45

# Define `N` as the sample size
N <- 100

# Use the `set.seed` function to make sure your answer matches the expected result after random sampling
set.seed(1)

# Define `X` as a random sample of `N` voters with a probability of picking a Democrat ('1') equal to `p`
X <- sample(c(1,0), N, replace = TRUE, prob = c(p, 1-p))
X
# Define `X_bar` as the average sampled proportion
X_bar <- mean(X)
X_bar
# Calculate the standard error of the estimate. Print the result to the console.
sqrt((X_bar * (1-X_bar))/N)

```

## Exercise 8. Plotting the standard error

![](images/clipboard-1311434742.png)

```{r}
N <- seq(100, 5000, len = 100)
p <- 0.5
se <- sqrt(p*(1-p)/N)
plot(se, N)
```

![![](images/clipboard-2298647615.png)](images/clipboard-1973722717.png)

## Exercise 9. Distribution of X-hat

![](images/clipboard-2372815898.png)

![](images/clipboard-2438765111.png)

## Exercise 10. Distribution of the errors

![](images/clipboard-705616515.png)

![](images/clipboard-2213686483.png)

## Exercise 11. Plotting the errors

Make a qq-plot of the `errors` you generated previously to see if they follow a normal distribution.

-   Run the supplied code

-   Use the `qqnorm` function to produce a qq-plot of the errors.

-   Use the `qqline` function to plot a line showing a normal distribution.

```{r}
# Define `p` as the proportion of Democrats in the population being polled
p <- 0.45

# Define `N` as the number of people polled
N <- 100

# The variable `B` specifies the number of times we want the sample to be replicated
B <- 10000

# Use the `set.seed` function to make sure your answer matches the expected result after random sampling
set.seed(1)

# Generate `errors` by subtracting the estimate from the actual proportion of Democratic voters
errors <- replicate(B, p - take_sample(p, N))

# Generate a qq-plot of `errors` with a qq-line showing a normal distribution
qqnorm(errors)
qqline(errors)
```

## Exercise 12. Estimating the probability of a specific value of X-bar

![](images/clipboard-1196500618.png)

-   Use `pnorm` to define the probability that a value will be greater than 0.5.

![](images/clipboard-3536925196.png)

```{r}
# Define `p` as the proportion of Democrats in the population being polled
p <- 0.45

# Define `N` as the number of people polled
N <- 100

# Calculate the probability that the estimated proportion of Democrats in the population is greater than 0.5. Print this value to the console.
1-pnorm(0.5, p, sqrt(p*(1-p)/N))
```

## Exercise 13. Estimating the probability of a specific error size

![](images/clipboard-5542308.png)

-   Calculate the standard error of the sample average using the `sqrt` function.

-   Use `pnorm` twice to define the probabilities that a value will be less than -0.01 or greater than 0.01.

-   Combine these results to calculate the probability that the error *size* will be 0.01 or larger.

```{r}
# Define `N` as the number of people polled
N <-100

# Define `X_hat` as the sample average
X_hat <- 0.51

# Define `se_hat` as the standard error of the sample average
se_hat <- sqrt(X_hat*(1-X_hat)/N)

# Calculate the probability that the error is 0.01 or larger
1-(pnorm(0.01/se_hat) - pnorm(-0.01/se_hat))
```

Note: CLT works if Xbar i used in place of p. Plug-in estimate.

# Section 3 Overview

In Section 3, you will look at confidence intervals and p-values.

After completing Section 3, you will be able to:

-   Calculate confidence intervals of difference sizes around an estimate.

-   Understand that a confidence interval is a random interval with the given probability of falling on top of the parameter.

-   Explain the concept of "power" as it relates to inference.

-   Understand the relationship between p-values and confidence intervals and explain why reporting confidence intervals is often preferable.

## Confidence Intervals

![](images/clipboard-3124435332.png)

### Code: geom_smooth confidence interval example

The shaded area around the curve is related to the concept of confidence intervals.

```{r}
data("nhtemp")
data.frame(year = as.numeric(time(nhtemp)), temperature = as.numeric(nhtemp)) %>%
    ggplot(aes(year, temperature)) +
    geom_point() +
    geom_smooth() +
    ggtitle("Average Yearly Temperatures in New Haven")
```

### Code: Monte Carlo simulation of confidence intervals

Note that to compute the exact 95% confidence interval, we would use qnorm(.975)\*SE_hat instead of 2\*SE_hat.

```{r}
p <- 0.45
N <- 1000
X <- sample(c(0,1), size = N, replace = TRUE, prob = c(1-p, p))    # generate N observations
X_hat <- mean(X)    # calculate X_hat
SE_hat <- sqrt(X_hat*(1-X_hat)/N)    # calculate SE_hat, SE of the mean of N observations
c(X_hat - 2*SE_hat, X_hat + 2*SE_hat)    # build interval of 2*SE above and below mean
```

### Code: Solving for z with `qnorm`

```{r}
z <- qnorm(0.995)    # calculate z to solve for 99% confidence interval
pnorm(qnorm(0.995))    # demonstrating that qnorm gives the z value for a given probability
pnorm(qnorm(1-0.995))    # demonstrating symmetry of 1-qnorm
pnorm(z) - pnorm(-z)    # demonstrating that this z value gives correct probability for interval
```

## A Visual Clarification of Confidence Intervals

![A common source of confusion is why `qnorm(.975)` is used rather than `qnorm(.95)` to find the 95% confidence interval. This is because the normal distribution is symmetric and our confidence interval should cover the middle 95% of the distribution:](images/clipboard-3989755348.png)

![![](images/clipboard-390637980.png)](images/ci95.png)
