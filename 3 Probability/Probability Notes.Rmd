---
title: "Probability Notes"
author: "natsuMishi"
date: "2023-12-25"
output: html_document
---

# Section 2 Overview

Section 2 introduces you to Continuous Probability.

After completing Section 2, you will:

-   understand the differences between calculating probabilities for discrete and continuous data.

-   be able to use cumulative distribution functions to assign probabilities to intervals when dealing with continuous data.

-   be able to use R to generate normally distributed outcomes for use in Monte Carlo simulations.

-   know some of the useful theoretical continuous distributions in addition to the normal distribution, such as the student-t, chi-squared, exponential, gamma, beta, and beta-binomial distributions.

# 2.1 Continuous Probability

## Continuous Probability

![](images/clipboard-2810912530.png)

### Code: Cumulative distribution function

Define `x` as male heights from the **dslabs** `heights` dataset:

```{r}
library(tidyverse)
library(dslabs)
data(heights)
x <- heights %>% filter(sex=="Male") %>% pull(height)
```

Given a vector **`x`**, we can define a function for computing the CDF of **`x`** using:

```{r}
F <- function(a) mean(x <= a)
1 - F(70)    # probability of male taller than 70 inches
```

## Theoretical Distribution

### Code: Using `pnorm()` to calculate probabilities

Given male heights `x`:

```{r}
library(tidyverse)
library(dslabs)
data(heights)
x <- heights %>% filter(sex=="Male") %>% pull(height)
```

We can estimate the probability that a male is taller than 70.5 inches using:

```{r}
1 - pnorm(70.5, mean(x), sd(x))
```

### Code: Discretization and the normal approximation

```{r}
# plot distribution of exact heights in data
plot(prop.table(table(x)), xlab = "a = Height in inches", ylab = "Pr(x = a)")

# probabilities in actual data over length 1 ranges containing an integer
mean(x <= 68.5) - mean(x <= 67.5)
mean(x <= 69.5) - mean(x <= 68.5)
mean(x <= 70.5) - mean(x <= 69.5)

# probabilities in normal approximation match well
pnorm(68.5, mean(x), sd(x)) - pnorm(67.5, mean(x), sd(x))
pnorm(69.5, mean(x), sd(x)) - pnorm(68.5, mean(x), sd(x))
pnorm(70.5, mean(x), sd(x)) - pnorm(69.5, mean(x), sd(x))

# probabilities in actual data over other ranges don't match normal approx as well
mean(x <= 70.9) - mean(x <= 70.1)
pnorm(70.9, mean(x), sd(x)) - pnorm(70.1, mean(x), sd(x))
```

## Probability Density

### ![](images/clipboard-383564387.png)

```{r}
avg <- mean(x)
s <- sd(x)
1 - pnorm(76, avg, s)
```

![](images/clipboard-2948622746.png)

The curve is the probability density function for the normal distribution.

## Plotting the Probability Density

### Plotting the probability density for the normal distribution

![](images/clipboard-6192111.png)

We can use `dnorm()` to plot the density curve for the normal distribution. `dnorm(z)` gives the probability density of a certain z-score, so we can draw a curve by calculating the density over a range of possible values of z.

First, we generate a series of z-scores covering the typical range of the normal distribution. Since we know 99.7% of observations will be within , we can use a value of slightly larger than 3 and this will cover most likely values of the normal distribution. Then, we calculate , which is `dnorm()` of the series of z-scores. Last, we plot against .

```{r}
library(tidyverse)
x <- seq(-4, 4, length = 100)
data.frame(x, f = dnorm(x)) %>%
    ggplot(aes(x, f)) +
    geom_line()
```

Here is the resulting plot:

![](images/clipboard-679013542.png)

Note that `dnorm()` gives densities for the standard normal distribution by default. Probabilities for alternative normal distributions with mean `mu` and standard deviation `sigma` can be evaluated with:

```{r}
dnorm(z, mu, sigma)
```

## Monte Carlo Simulations

### Monte Carlo Simulations

`rnorm(n, avg, s)` generates `n` random numbers from the normal distribution with average `avg` and standard deviation `s`.

By generating random numbers from the normal distribution, we can simulate height data with similar properties to our dataset. Here we generate simulated height data using the normal distribution.

### Code: Generating normally distributed random numbers

```{r}
# define x as male heights from dslabs data
library(tidyverse)
library(dslabs)
data(heights)
x <- heights %>% filter(sex=="Male") %>% pull(height)

# generate simulated height data using normal distribution - both datasets should have n observations
n <- length(x)
avg <- mean(x)
s <- sd(x)
simulated_heights <- rnorm(n, avg, s)

# plot distribution of simulated_heights
data.frame(simulated_heights = simulated_heights) %>%
    ggplot(aes(simulated_heights)) +
    geom_histogram(color="black", binwidth = 2)
```

### Code: Monte Carlo simulation of tallest person over 7 feet

```{r}
B <- 10000
tallest <- replicate(B, {
    simulated_data <- rnorm(800, avg, s)    # generate 800 normally distributed random heights
    max(simulated_data)    # determine the tallest height
})
mean(tallest >= 7*12)    # proportion of times that tallest person exceeded 7 feet (84 inches)
```

## Other continuous distributions

-   You may encounter other continuous distributions (Student t, chi-squared, exponential, gamma, beta, etc.).

-   R provides functions for density (`d`), quantile (`q`), probability distribution (`p`) and random number generation (`r`) for many of these distributions.

-   Each distribution has a matching abbreviation (for example, `norm()` or `t()`) that is paired with the related function abbreviations (**`d`**`, p, q, r`) to create appropriate functions.

-   For example, use `rt()` to generate random numbers for a Monte Carlo simulation using the Student t distribution.

### Code: Plotting the normal distribution with dnorm

Use d to plot the density function of a continuous distribution. Here is the density function for the normal distribution (abbreviation `norm()`):

```{r}
x <- seq(-4, 4, length.out = 100)
data.frame(x, f = dnorm(x)) %>%
    ggplot(aes(x,f)) +
    geom_line()
```

# Section 3 Overview

Section 3 introduces you to Random Variables, Sampling Models, and the Central Limit Theorem.

Section 3 is divided into two parts:

1.  Random Variables and Sampling Models

2.  The Central Limit Theorem.

After completing Section 3, you will:

-   understand what random variables are, how to generate them, and the correct mathematical notation to use with them.

-   be able to use sampling models to estimate characteristics of a larger population.

-   be able to explain the difference between a distribution and a probability distribution.

-   understand the Central Limit Theorem and the law of large numbers.

There are 2 assignments that use the DataCamp platform for you to practice your coding skills as well as a set of questions on the edX platform at the end of Section 3.

# 3.1 Random Variables and Sampling Models

### Random Variables

-   Random variables are numeric outcomes resulting from random processes.

-   Statistical inference offers a framework for quantifying uncertainty due to randomness.

### Code: Modeling a random variable

```{r}
# define random variable x to be 1 if blue, 0 otherwise
beads <- rep(c("red", "blue"), times = c(2, 3))
x <- ifelse(sample(beads, 1) == "blue", 1, 0)

# demonstrate that the random variable is different every time
ifelse(sample(beads, 1) == "blue", 1, 0)
ifelse(sample(beads, 1) == "blue", 1, 0)
ifelse(sample(beads, 1) == "blue", 1, 0)
```

### Sampling Models

![](images/clipboard-2090246089.png)

-   A sampling model models the random behavior of a process as the sampling of draws from an urn.
-   The **probability distribution of a random variable** is the probability of the observed value falling in any given interval.
-   We can define a CDF to answer questions related to the probability of S being in any interval.
-   The average of many draws of a random variable is called its **expected value**.
-   The standard deviation of many draws of a random variable is called its **standard error**.

### Monte Carlo simulation: Chance of casino losing money on roulette

We build a sampling model for the random variable S that represents the casino's total winnings. 

```{r}
# sampling model 1: define urn, then sample
color <- rep(c("Black", "Red", "Green"), c(18, 18, 2)) # define the urn for the sampling model
n <- 1000
X <- sample(ifelse(color == "Red", -1, 1), n, replace = TRUE)
X[1:10]

# sampling model 2: define urn inside sample function by noting probabilities
x <- sample(c(-1, 1), n, replace = TRUE, prob = c(9/19, 10/19))    # 1000 independent draws
S <- sum(x)    # total winnings = sum of draws
S #S is a random variable
```

We use the sampling model to run a Monte Carlo simulation and use the results to estimate the probability of the casino losing money.

```{r}
n <- 1000    # number of roulette players
B <- 10000    # number of Monte Carlo experiments
S <- replicate(B, {
    X <- sample(c(-1,1), n, replace = TRUE, prob = c(9/19, 10/19))    # simulate 1000 spins
    sum(X)    # determine total profit
})

mean(S < 0)    # probability of the casino losing money
```

We can plot a histogram of the observed values of S as well as the normal density curve based on the mean and standard deviation of S. Calculated simply with

```{r}
sd(S)
mean(S)
```

```{r}
library(tidyverse)
s <- seq(min(S), max(S), length = 100)    # sequence of 100 values across range of S
normal_density <- data.frame(s = s, f = dnorm(s, mean(S), sd(S))) # generate normal density for S
data.frame (S = S) %>%    # make data frame of S for histogram
    ggplot(aes(S, ..density..)) +
    geom_histogram(color = "black", binwidth = 10) +
    ylab("Probability") +
    geom_line(data = normal_density, mapping = aes(s, f), color = "blue")
```

Use QQ-plot to confirm that the normal approximation is close to perfect.

### Distributions versus Probability Distributions

![](images/clipboard-827801095.png)

-   A random variable has a probability distribution function that defines over all values of .
-   Any list of numbers has a distribution. The probability distribution function of a random variable is defined mathematically and does not depend on a list of numbers.
-   The results of a Monte Carlo simulation with a large enough number of observations will approximate the probability distribution of .
-   If a random variable is defined as draws from an urn:
    -   The probability distribution function of the random variable is defined as the distribution of the list of values in the urn.

    -   The expected value of the random variable is the average of values in the urn.

    -   The standard error of one draw of the random variable is the standard deviation of the values of the urn.

### Notation for Random Variables

![](images/clipboard-2504381508.png)

-   Capital letters denote random variables () and lowercase letters denote observed values ().
-   In the notation , we are asking how frequently the random variable is equal to the value . For example, if , this statement becomes .

### Central Limit Theorem

![](images/clipboard-3299349822.png)

```{r}
B <- 10^6 #million games
X <- sample(c(-1,1), B, replace = TRUE, prob = c(9/19, 10/19))
mean(X)
```

![](images/clipboard-1157300129.png)

-   The Central Limit Theorem (CLT) says that the distribution of the sum of a random variable is approximated by a normal distribution.
-   The expected value of a random variable, , is the average of the values in the urn. This represents the expectation of one draw. 
-   The standard error of one draw of a random variable is the standard deviation of the values in the urn.
-   The expected value of the sum of draws is the number of draws times the expected value of the random variable. 
-   The standard error of the sum of independent draws of a random variable is the square root of the number of draws times the standard deviation of the urn. 

These equations apply to the case where there are only two outcomes, and with proportions and respectively. The general principles above also apply to random variables with more than two outcomes.

*Expected value of a random variable:* 

*Expected value of the sum of n draws of a random variable:* 

*Standard deviation of an urn with two values:* 

*Standard error of the sum of n draws of a random variable:*

```{r}
n <- 1000
sqrt(n) * 2 * sqrt(90/19)
#How likely is the casino to lose money?
mu <- n*(20-18)/38
se <- sqrt(n) * 2 * sqrt(90)/19
pnorm(0, mu, se)
```

# DataCamp Assessment: Random Variables and Sampling Models
